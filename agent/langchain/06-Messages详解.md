# Messages è¯¦è§£

Messages æ˜¯ LangChain ä¸­æ¨¡å‹ä¸Šä¸‹æ–‡çš„åŸºæœ¬å•ä½ã€‚å®ƒä»¬è¡¨ç¤ºæ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºï¼Œæºå¸¦ä¸ LLM äº¤äº’æ—¶è¡¨ç¤ºå¯¹è¯çŠ¶æ€æ‰€éœ€çš„å†…å®¹å’Œå…ƒæ•°æ®ã€‚

Message å¯¹è±¡åŒ…å«ï¼š

- ğŸ‘¤ **Roleï¼ˆè§’è‰²ï¼‰** - æ ‡è¯†æ¶ˆæ¯ç±»å‹ï¼ˆå¦‚ `system`ã€`user`ï¼‰
- ğŸ“ **Contentï¼ˆå†…å®¹ï¼‰** - è¡¨ç¤ºæ¶ˆæ¯çš„å®é™…å†…å®¹ï¼ˆå¦‚æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€æ–‡æ¡£ç­‰ï¼‰
- ğŸ·ï¸ **Metadataï¼ˆå…ƒæ•°æ®ï¼‰** - å¯é€‰å­—æ®µï¼Œå¦‚å“åº”ä¿¡æ¯ã€æ¶ˆæ¯ ID å’Œ token ä½¿ç”¨é‡

LangChain æä¾›äº†è·¨æ‰€æœ‰æ¨¡å‹æä¾›å•†å·¥ä½œçš„æ ‡å‡†æ¶ˆæ¯ç±»å‹ï¼Œç¡®ä¿æ— è®ºè°ƒç”¨å“ªä¸ªæ¨¡å‹éƒ½æœ‰ä¸€è‡´çš„è¡Œä¸ºã€‚

## åŸºæœ¬ç”¨æ³•

åˆ›å»ºæ¶ˆæ¯å¯¹è±¡å¹¶åœ¨è°ƒç”¨æ¨¡å‹æ—¶ä¼ é€’å®ƒä»¬ï¼š

```python
from langchain.chat_models import init_chat_model
from langchain.messages import HumanMessage, AIMessage, SystemMessage

model = init_chat_model("gpt-4o")

system_msg = SystemMessage("ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚")
human_msg = HumanMessage("ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ")

messages = [system_msg, human_msg]
response = model.invoke(messages)  # è¿”å› AIMessage
```

### ä¸‰ç§è¾“å…¥æ–¹å¼

#### 1. æ–‡æœ¬æç¤ºï¼ˆå­—ç¬¦ä¸²ï¼‰

æœ€ç®€å•çš„æ–¹å¼ï¼Œé€‚ç”¨äºä¸éœ€è¦ä¿ç•™å¯¹è¯å†å²çš„å•æ¬¡è¯·æ±‚ï¼š

```python
response = model.invoke("å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„ä¿³å¥")
```

#### 2. æ¶ˆæ¯åˆ—è¡¨ï¼ˆMessage å¯¹è±¡ï¼‰

é€‚ç”¨äºç®¡ç†å¤šè½®å¯¹è¯ã€å¤„ç†å¤šæ¨¡æ€å†…å®¹æˆ–åŒ…å«ç³»ç»ŸæŒ‡ä»¤ï¼š

```python
from langchain.messages import SystemMessage, HumanMessage, AIMessage

messages = [
    SystemMessage("ä½ æ˜¯ä¸€ä¸ªè¯—æ­Œä¸“å®¶"),
    HumanMessage("å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„ä¿³å¥"),
    AIMessage("æ¨±èŠ±ç»½æ”¾æ—¶...")
]
response = model.invoke(messages)
```

#### 3. å­—å…¸æ ¼å¼ï¼ˆOpenAI å…¼å®¹ï¼‰

ç›´æ¥ä½¿ç”¨ OpenAI èŠå¤©å®Œæˆæ ¼å¼ï¼š

```python
messages = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè¯—æ­Œä¸“å®¶"},
    {"role": "user", "content": "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„ä¿³å¥"},
    {"role": "assistant", "content": "æ¨±èŠ±ç»½æ”¾æ—¶..."}
]
response = model.invoke(messages)
```

## æ¶ˆæ¯ç±»å‹

### SystemMessageï¼ˆç³»ç»Ÿæ¶ˆæ¯ï¼‰

è®¾ç½®æ¨¡å‹è¡Œä¸ºçš„åˆå§‹æŒ‡ä»¤ï¼Œç”¨äºå®šä¹‰æ¨¡å‹çš„è§’è‰²ã€è¯­æ°”å’Œå“åº”å‡†åˆ™ã€‚

```python
from langchain.messages import SystemMessage, HumanMessage

# åŸºæœ¬æŒ‡ä»¤
system_msg = SystemMessage("ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„ç¼–ç¨‹åŠ©æ‰‹ã€‚")

# è¯¦ç»†äººè®¾
system_msg = SystemMessage("""ä½ æ˜¯ä¸€ä¸ªèµ„æ·± Python å¼€å‘è€…ï¼Œä¸“ç²¾äº Web æ¡†æ¶ã€‚
å§‹ç»ˆæä¾›ä»£ç ç¤ºä¾‹å¹¶è§£é‡Šä½ çš„æ¨ç†ã€‚
è§£é‡Šè¦ç®€æ´ä½†å…¨é¢ã€‚""")

messages = [system_msg, HumanMessage("å¦‚ä½•åˆ›å»º REST APIï¼Ÿ")]
response = model.invoke(messages)
```

### HumanMessageï¼ˆç”¨æˆ·æ¶ˆæ¯ï¼‰

è¡¨ç¤ºç”¨æˆ·è¾“å…¥å’Œäº¤äº’ï¼Œå¯ä»¥åŒ…å«æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€æ–‡ä»¶ç­‰å¤šæ¨¡æ€å†…å®¹ã€‚

```python
from langchain.messages import HumanMessage

# æ–‡æœ¬å†…å®¹
human_msg = HumanMessage("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")

# å¸¦å…ƒæ•°æ®
human_msg = HumanMessage(
    content="ä½ å¥½ï¼",
    name="alice",      # å¯é€‰ï¼šæ ‡è¯†ä¸åŒç”¨æˆ·
    id="msg_123",      # å¯é€‰ï¼šç”¨äºè¿½è¸ªçš„å”¯ä¸€æ ‡è¯†ç¬¦
)

# å­—ç¬¦ä¸²æ˜¯å•ä¸ª HumanMessage çš„å¿«æ·æ–¹å¼
response = model.invoke("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")
# ç­‰åŒäº
response = model.invoke([HumanMessage("ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ")])
```

### AIMessageï¼ˆAI æ¶ˆæ¯ï¼‰

è¡¨ç¤ºæ¨¡å‹è°ƒç”¨çš„è¾“å‡ºï¼Œå¯ä»¥åŒ…å«å¤šæ¨¡æ€æ•°æ®ã€å·¥å…·è°ƒç”¨å’Œæä¾›å•†ç‰¹å®šçš„å…ƒæ•°æ®ã€‚

```python
response = model.invoke("è§£é‡Š AI")
print(type(response))  # <class 'langchain.messages.AIMessage'>
```

#### ä¸»è¦å±æ€§

| å±æ€§ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `text` | string | æ¶ˆæ¯çš„æ–‡æœ¬å†…å®¹ |
| `content` | string \| dict[] | æ¶ˆæ¯çš„åŸå§‹å†…å®¹ |
| `content_blocks` | ContentBlock[] | æ ‡å‡†åŒ–çš„å†…å®¹å— |
| `tool_calls` | dict[] \| None | æ¨¡å‹å‘èµ·çš„å·¥å…·è°ƒç”¨ |
| `id` | string | æ¶ˆæ¯çš„å”¯ä¸€æ ‡è¯†ç¬¦ |
| `usage_metadata` | dict \| None | ä½¿ç”¨å…ƒæ•°æ®ï¼ˆtoken è®¡æ•°ç­‰ï¼‰ |
| `response_metadata` | dict \| None | å“åº”å…ƒæ•°æ® |

#### æ‰‹åŠ¨åˆ›å»º AIMessage

æœ‰æ—¶éœ€è¦æ‰‹åŠ¨åˆ›å»º AIMessage å¹¶æ’å…¥åˆ°æ¶ˆæ¯å†å²ä¸­ï¼š

```python
from langchain.messages import AIMessage, SystemMessage, HumanMessage

# æ‰‹åŠ¨åˆ›å»º AI æ¶ˆæ¯ï¼ˆä¾‹å¦‚ç”¨äºå¯¹è¯å†å²ï¼‰
ai_msg = AIMessage("æˆ‘å¾ˆä¹æ„å¸®åŠ©ä½ è§£ç­”è¿™ä¸ªé—®é¢˜ï¼")

# æ·»åŠ åˆ°å¯¹è¯å†å²
messages = [
    SystemMessage("ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹"),
    HumanMessage("ä½ èƒ½å¸®æˆ‘å—ï¼Ÿ"),
    ai_msg,  # æ’å…¥ï¼Œå°±åƒå®ƒæ¥è‡ªæ¨¡å‹ä¸€æ ·
    HumanMessage("å¤ªå¥½äº†ï¼2+2 ç­‰äºå¤šå°‘ï¼Ÿ")
]
response = model.invoke(messages)
```

#### å·¥å…·è°ƒç”¨

å½“æ¨¡å‹è¿›è¡Œå·¥å…·è°ƒç”¨æ—¶ï¼Œå®ƒä»¬åŒ…å«åœ¨ AIMessage ä¸­ï¼š

```python
from langchain.chat_models import init_chat_model

model = init_chat_model("gpt-4o")

def get_weather(location: str) -> str:
    """è·å–æŒ‡å®šä½ç½®çš„å¤©æ°”"""
    ...

model_with_tools = model.bind_tools([get_weather])
response = model_with_tools.invoke("å·´é»çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ")

for tool_call in response.tool_calls:
    print(f"å·¥å…·: {tool_call['name']}")
    print(f"å‚æ•°: {tool_call['args']}")
    print(f"ID: {tool_call['id']}")
```

#### Token ä½¿ç”¨é‡

```python
response = model.invoke("ä½ å¥½ï¼")
print(response.usage_metadata)
# {
#   'input_tokens': 8,
#   'output_tokens': 304,
#   'total_tokens': 312,
#   'input_token_details': {'audio': 0, 'cache_read': 0},
#   'output_token_details': {'audio': 0, 'reasoning': 256}
# }
```

#### æµå¼è¾“å‡ºå’Œ Chunks

åœ¨æµå¼è¾“å‡ºæœŸé—´ï¼Œä½ ä¼šæ”¶åˆ° `AIMessageChunk` å¯¹è±¡ï¼Œå¯ä»¥ç»„åˆæˆå®Œæ•´çš„æ¶ˆæ¯ï¼š

```python
chunks = []
full_message = None

for chunk in model.stream("ä½ å¥½"):
    chunks.append(chunk)
    print(chunk.text)
    full_message = chunk if full_message is None else full_message + chunk
```

### ToolMessageï¼ˆå·¥å…·æ¶ˆæ¯ï¼‰

ç”¨äºå°†å•ä¸ªå·¥å…·æ‰§è¡Œçš„ç»“æœä¼ å›æ¨¡å‹ã€‚

```python
from langchain.messages import AIMessage, ToolMessage, HumanMessage

# æ¨¡å‹å‘èµ·å·¥å…·è°ƒç”¨å
ai_message = AIMessage(
    content=[],
    tool_calls=[{
        "name": "get_weather",
        "args": {"location": "æ—§é‡‘å±±"},
        "id": "call_123"
    }]
)

# æ‰§è¡Œå·¥å…·å¹¶åˆ›å»ºç»“æœæ¶ˆæ¯
weather_result = "æ™´å¤©ï¼Œ72Â°F"
tool_message = ToolMessage(
    content=weather_result,
    tool_call_id="call_123"  # å¿…é¡»åŒ¹é…è°ƒç”¨ ID
)

# ç»§ç»­å¯¹è¯
messages = [
    HumanMessage("æ—§é‡‘å±±çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"),
    ai_message,      # æ¨¡å‹çš„å·¥å…·è°ƒç”¨
    tool_message,    # å·¥å…·æ‰§è¡Œç»“æœ
]
response = model.invoke(messages)  # æ¨¡å‹å¤„ç†ç»“æœ
```

#### ToolMessage å±æ€§

| å±æ€§ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `content` | string | å·¥å…·è°ƒç”¨çš„å­—ç¬¦ä¸²åŒ–è¾“å‡ºï¼ˆå¿…éœ€ï¼‰ |
| `tool_call_id` | string | æ­¤æ¶ˆæ¯å“åº”çš„å·¥å…·è°ƒç”¨ IDï¼ˆå¿…éœ€ï¼‰ |
| `name` | string | è¢«è°ƒç”¨çš„å·¥å…·åç§°ï¼ˆå¿…éœ€ï¼‰ |
| `artifact` | dict | ä¸å‘é€ç»™æ¨¡å‹ä½†å¯ä»¥ç¨‹åºåŒ–è®¿é—®çš„é™„åŠ æ•°æ® |

#### artifact å­—æ®µ

`artifact` å­—æ®µå­˜å‚¨ä¸ä¼šå‘é€ç»™æ¨¡å‹ä½†å¯ä»¥ç¨‹åºåŒ–è®¿é—®çš„è¡¥å……æ•°æ®ï¼Œé€‚ç”¨äºå­˜å‚¨åŸå§‹ç»“æœã€è°ƒè¯•ä¿¡æ¯æˆ–ä¸‹æ¸¸å¤„ç†çš„æ•°æ®ï¼š

```python
from langchain.messages import ToolMessage

# å‘é€ç»™æ¨¡å‹çš„å†…å®¹
message_content = "è¿™æ˜¯æœ€å¥½çš„æ—¶ä»£ï¼Œè¿™æ˜¯æœ€åçš„æ—¶ä»£ã€‚"

# ä¸‹æ¸¸å¯ç”¨çš„ artifact
artifact = {"document_id": "doc_123", "page": 0}

tool_message = ToolMessage(
    content=message_content,
    tool_call_id="call_123",
    name="search_books",
    artifact=artifact,
)
```

## æ¶ˆæ¯å†…å®¹

æ¶ˆæ¯çš„å†…å®¹æ˜¯å‘é€ç»™æ¨¡å‹çš„æ•°æ®è½½ä½“ã€‚`content` å±æ€§æ”¯æŒå­—ç¬¦ä¸²å’Œæ— ç±»å‹å¯¹è±¡åˆ—è¡¨ï¼ˆå¦‚å­—å…¸ï¼‰ï¼Œå…è®¸ç›´æ¥åœ¨ LangChain èŠå¤©æ¨¡å‹ä¸­æ”¯æŒæä¾›å•†åŸç”Ÿç»“æ„ã€‚

### å†…å®¹æ ¼å¼

```python
from langchain.messages import HumanMessage

# 1. å­—ç¬¦ä¸²å†…å®¹
human_message = HumanMessage("ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ")

# 2. æä¾›å•†åŸç”Ÿæ ¼å¼ï¼ˆå¦‚ OpenAIï¼‰
human_message = HumanMessage(content=[
    {"type": "text", "text": "ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ"},
    {"type": "image_url", "image_url": {"url": "https://example.com/image.jpg"}}
])

# 3. æ ‡å‡†å†…å®¹å—åˆ—è¡¨
human_message = HumanMessage(content_blocks=[
    {"type": "text", "text": "ä½ å¥½ï¼Œä½ å¥½å—ï¼Ÿ"},
    {"type": "image", "url": "https://example.com/image.jpg"},
])
```

### æ ‡å‡†å†…å®¹å—

LangChain æä¾›äº†è·¨æä¾›å•†å·¥ä½œçš„æ ‡å‡†æ¶ˆæ¯å†…å®¹è¡¨ç¤ºã€‚

#### æ ¸å¿ƒå—

**TextContentBlock** - æ ‡å‡†æ–‡æœ¬è¾“å‡º

```python
{
    "type": "text",
    "text": "Hello world",
    "annotations": []
}
```

**ReasoningContentBlock** - æ¨¡å‹æ¨ç†æ­¥éª¤

```python
{
    "type": "reasoning",
    "reasoning": "ç”¨æˆ·åœ¨é—®å…³äº...",
    "extras": {"signature": "abc123"}
}
```

#### å¤šæ¨¡æ€å—

**ImageContentBlock** - å›¾åƒæ•°æ®

```python
# ä» URL
{"type": "image", "url": "https://example.com/image.jpg"}

# ä» base64
{
    "type": "image",
    "base64": "AAAAIGZ0eXBtcDQy...",
    "mime_type": "image/jpeg"
}

# ä»æä¾›å•†ç®¡ç†çš„æ–‡ä»¶ ID
{"type": "image", "file_id": "file-abc123"}
```

**AudioContentBlock** - éŸ³é¢‘æ•°æ®

```python
{
    "type": "audio",
    "base64": "AAAAIGZ0eXBtcDQy...",
    "mime_type": "audio/wav"
}
```

**VideoContentBlock** - è§†é¢‘æ•°æ®

```python
{
    "type": "video",
    "base64": "AAAAIGZ0eXBtcDQy...",
    "mime_type": "video/mp4"
}
```

**FileContentBlock** - é€šç”¨æ–‡ä»¶ï¼ˆPDF ç­‰ï¼‰

```python
# ä» URL
{"type": "file", "url": "https://example.com/document.pdf"}

# ä» base64
{
    "type": "file",
    "base64": "AAAAIGZ0eXBtcDQy...",
    "mime_type": "application/pdf"
}
```

#### å·¥å…·è°ƒç”¨å—

**ToolCall** - å‡½æ•°è°ƒç”¨

```python
{
    "type": "tool_call",
    "name": "search",
    "args": {"query": "weather"},
    "id": "call_123"
}
```

**ToolCallChunk** - æµå¼å·¥å…·è°ƒç”¨ç‰‡æ®µ

```python
{
    "type": "tool_call_chunk",
    "name": "search",
    "args": "{\"query\":",  # å¯èƒ½æ˜¯ä¸å®Œæ•´çš„ JSON
    "id": "call_123",
    "index": 0
}
```

**InvalidToolCall** - æ ¼å¼é”™è¯¯çš„è°ƒç”¨ï¼ˆç”¨äºæ•è· JSON è§£æé”™è¯¯ï¼‰

```python
{
    "type": "invalid_tool_call",
    "name": "search",
    "args": {},
    "error": "JSON è§£æå¤±è´¥"
}
```

#### æœåŠ¡å™¨ç«¯å·¥å…·æ‰§è¡Œå—

**ServerToolCall** - æœåŠ¡å™¨ç«¯æ‰§è¡Œçš„å·¥å…·è°ƒç”¨

```python
{
    "type": "server_tool_call",
    "id": "call_123",
    "name": "web_search",
    "args": {"query": "..."}
}
```

**ServerToolResult** - æœåŠ¡å™¨ç«¯å·¥å…·ç»“æœ

```python
{
    "type": "server_tool_result",
    "tool_call_id": "call_123",
    "status": "success",  # æˆ– "error"
    "output": "..."
}
```

## å¤šæ¨¡æ€è¾“å…¥ç¤ºä¾‹

### å›¾åƒè¾“å…¥

```python
# ä» URL
message = {
    "role": "user",
    "content": [
        {"type": "text", "text": "æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚"},
        {"type": "image", "url": "https://example.com/path/to/image.jpg"},
    ]
}

# ä» base64 æ•°æ®
message = {
    "role": "user",
    "content": [
        {"type": "text", "text": "æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚"},
        {
            "type": "image",
            "base64": "AAAAIGZ0eXBtcDQy...",
            "mime_type": "image/jpeg"
        },
    ]
}
```

### PDF æ–‡æ¡£è¾“å…¥

```python
message = {
    "role": "user",
    "content": [
        {"type": "text", "text": "æè¿°è¿™ä¸ªæ–‡æ¡£çš„å†…å®¹ã€‚"},
        {"type": "file", "url": "https://example.com/path/to/document.pdf"},
    ]
}
```

### éŸ³é¢‘è¾“å…¥

```python
message = {
    "role": "user",
    "content": [
        {"type": "text", "text": "æè¿°è¿™æ®µéŸ³é¢‘çš„å†…å®¹ã€‚"},
        {
            "type": "audio",
            "base64": "AAAAIGZ0eXBtcDQy...",
            "mime_type": "audio/wav"
        },
    ]
}
```

### è§†é¢‘è¾“å…¥

```python
message = {
    "role": "user",
    "content": [
        {"type": "text", "text": "æè¿°è¿™ä¸ªè§†é¢‘çš„å†…å®¹ã€‚"},
        {
            "type": "video",
            "base64": "AAAAIGZ0eXBtcDQy...",
            "mime_type": "video/mp4"
        },
    ]
}
```

> âš ï¸ å¹¶éæ‰€æœ‰æ¨¡å‹éƒ½æ”¯æŒæ‰€æœ‰æ–‡ä»¶ç±»å‹ã€‚è¯·æŸ¥çœ‹æ¨¡å‹æä¾›å•†çš„æ–‡æ¡£äº†è§£æ”¯æŒçš„æ ¼å¼å’Œå¤§å°é™åˆ¶ã€‚

## å†…å®¹å—çš„æ ‡å‡†åŒ–

ä¸åŒæä¾›å•†è¿”å›çš„å†…å®¹æ ¼å¼å¯èƒ½ä¸åŒï¼Œä½† LangChain çš„ `content_blocks` å±æ€§ä¼šå°†å®ƒä»¬è§£æä¸ºæ ‡å‡†æ ¼å¼ï¼š

```python
from langchain.messages import AIMessage

# Anthropic æ ¼å¼
message = AIMessage(
    content=[
        {"type": "thinking", "thinking": "...", "signature": "WaUjzkyp..."},
        {"type": "text", "text": "..."},
    ],
    response_metadata={"model_provider": "anthropic"}
)

# è®¿é—®æ ‡å‡†åŒ–çš„å†…å®¹å—
print(message.content_blocks)
# [
#   {'type': 'reasoning', 'reasoning': '...', 'extras': {'signature': 'WaUjzkyp...'}},
#   {'type': 'text', 'text': '...'}
# ]
```

## ä¸èŠå¤©æ¨¡å‹é…åˆä½¿ç”¨

èŠå¤©æ¨¡å‹æ¥å—æ¶ˆæ¯å¯¹è±¡åºåˆ—ä½œä¸ºè¾“å…¥ï¼Œè¿”å› AIMessage ä½œä¸ºè¾“å‡ºã€‚äº¤äº’é€šå¸¸æ˜¯æ— çŠ¶æ€çš„ï¼Œå› æ­¤ç®€å•çš„å¯¹è¯å¾ªç¯æ¶‰åŠä½¿ç”¨ä¸æ–­å¢é•¿çš„æ¶ˆæ¯åˆ—è¡¨è°ƒç”¨æ¨¡å‹ã€‚

```python
from langchain.chat_models import init_chat_model
from langchain.messages import HumanMessage, AIMessage, SystemMessage

model = init_chat_model("gpt-4o")

# ç»´æŠ¤å¯¹è¯å†å²
messages = [SystemMessage("ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚")]

# ç¬¬ä¸€è½®
messages.append(HumanMessage("ä½ å¥½ï¼"))
response = model.invoke(messages)
messages.append(response)

# ç¬¬äºŒè½®
messages.append(HumanMessage("ä½ èƒ½å¸®æˆ‘å†™ä»£ç å—ï¼Ÿ"))
response = model.invoke(messages)
messages.append(response)

# messages ç°åœ¨åŒ…å«å®Œæ•´çš„å¯¹è¯å†å²
```

## æ€»ç»“

| æ¶ˆæ¯ç±»å‹ | ç”¨é€” | è§’è‰² |
|----------|------|------|
| SystemMessage | è®¾ç½®æ¨¡å‹è¡Œä¸ºå’Œä¸Šä¸‹æ–‡ | system |
| HumanMessage | ç”¨æˆ·è¾“å…¥å’Œäº¤äº’ | user |
| AIMessage | æ¨¡å‹ç”Ÿæˆçš„å“åº” | assistant |
| ToolMessage | å·¥å…·æ‰§è¡Œç»“æœ | tool |
