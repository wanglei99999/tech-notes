# 记忆系统详解

记忆系统让 Agent 能够记住之前的交互、从反馈中学习，并适应用户偏好。随着 Agent 处理越来越复杂的任务和大量用户交互，这种能力变得至关重要。

LangChain 提供两种记忆类型：

| 记忆类型 | 生命周期 | 存储内容 | 访问范围 | 典型用途 |
|----------|----------|----------|----------|----------|
| **短期记忆 (State)** | 当前会话 | 对话消息、临时状态 | 单次对话 | 上下文窗口管理 |
| **长期记忆 (Store)** | 跨会话持久化 | 用户偏好、历史数据、洞察 | 跨多次对话 | 用户画像、个性化 |

```mermaid
graph TB
    subgraph "短期记忆 (State)"
        S1[消息历史]
        S2[当前会话状态]
        S3[工具调用结果]
    end
    
    subgraph "长期记忆 (Store)"
        L1[用户偏好]
        L2[历史洞察]
        L3[跨会话数据]
    end
    
    Agent --> S1
    Agent --> S2
    Agent --> S3
    Agent --> L1
    Agent --> L2
    Agent --> L3
    
    S1 -.->|会话结束后丢失| X[❌]
    L1 -.->|持久化保存| DB[(数据库)]
```

## 目录

- [短期记忆（State）](#短期记忆state)
- [长期记忆（Store）](#长期记忆store)
- [记忆类型对比](#记忆类型对比)
- [最佳实践](#最佳实践)

---


## 短期记忆（State）

短期记忆让应用能够在单个线程或对话中记住之前的交互。

> **线程（Thread）** 类似于邮件中的会话，将多个交互组织在一起。

对话历史是最常见的短期记忆形式。但长对话对当前的 LLM 来说是个挑战：完整的历史可能无法放入 LLM 的上下文窗口，导致上下文丢失或错误。

即使模型支持完整的上下文长度，大多数 LLM 在长上下文中表现仍然不佳——它们会被陈旧或离题的内容"分散注意力"，同时响应速度变慢、成本增加。

### 基本用法

要为 Agent 添加短期记忆（线程级持久化），需要在创建 Agent 时指定 `checkpointer`：

```python
from langchain.agents import create_agent
from langgraph.checkpoint.memory import InMemorySaver

agent = create_agent(
    "gpt-4o",
    tools=[get_user_info],
    checkpointer=InMemorySaver(),  # 启用短期记忆
)

# 使用 thread_id 标识对话
agent.invoke(
    {"messages": [{"role": "user", "content": "你好！我叫小明。"}]},
    {"configurable": {"thread_id": "1"}},  # 同一个 thread_id 共享记忆
)
```

**工作原理：**

- LangChain 的 Agent 将短期记忆作为状态的一部分管理
- 通过将状态存储在图的状态中，Agent 可以访问给定对话的完整上下文，同时保持不同线程之间的隔离
- 状态通过 checkpointer 持久化到数据库（或内存），因此线程可以随时恢复
- 当 Agent 被调用或某个步骤（如工具调用）完成时，短期记忆会更新；在每个步骤开始时读取状态

#### 生产环境

在生产环境中，使用数据库支持的 checkpointer：

```bash
pip install langgraph-checkpoint-postgres
```

```python
from langchain.agents import create_agent
from langgraph.checkpoint.postgres import PostgresSaver

DB_URI = "postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable"

with PostgresSaver.from_conn_string(DB_URI) as checkpointer:
    checkpointer.setup()  # 自动在 PostgreSQL 中创建表
    
    agent = create_agent(
        "gpt-4o",
        tools=[get_user_info],
        checkpointer=checkpointer,
    )
```

### 自定义 Agent 记忆

默认情况下，Agent 使用 `AgentState` 管理短期记忆，通过 `messages` 键存储对话历史。

你可以扩展 `AgentState` 添加额外字段。自定义状态 schema 通过 `state_schema` 参数传递给 `create_agent`：

```python
from langchain.agents import create_agent, AgentState
from langgraph.checkpoint.memory import InMemorySaver

class CustomAgentState(AgentState):
    user_id: str           # 新增：用户 ID
    preferences: dict      # 新增：用户偏好

agent = create_agent(
    "gpt-4o",
    tools=[get_user_info],
    state_schema=CustomAgentState,  # 使用自定义状态
    checkpointer=InMemorySaver(),
)

# 调用时可以传入自定义状态
result = agent.invoke(
    {
        "messages": [{"role": "user", "content": "你好"}],
        "user_id": "user_123",              # 自定义字段
        "preferences": {"theme": "dark"}    # 自定义字段
    },
    {"configurable": {"thread_id": "1"}}
)
```


### 常见模式

启用短期记忆后，长对话可能超出 LLM 的上下文窗口。常见的解决方案：

| 方案 | 说明 |
|------|------|
| 裁剪消息 | 在调用 LLM 前移除前 N 条或后 N 条消息 |
| 删除消息 | 从 LangGraph 状态中永久删除消息 |
| 总结消息 | 总结早期消息并用摘要替换它们 |
| 自定义策略 | 消息过滤等自定义策略 |

这些方法让 Agent 能够跟踪对话而不超出 LLM 的上下文窗口。

#### 裁剪消息

决定何时截断消息的一种方法是计算消息历史中的 token 数，并在接近限制时截断。

使用 `@before_model` 中间件装饰器在 Agent 中裁剪消息历史：

```python
from langchain.messages import RemoveMessage
from langgraph.graph.message import REMOVE_ALL_MESSAGES
from langgraph.checkpoint.memory import InMemorySaver
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import before_model
from langgraph.runtime import Runtime
from langchain_core.runnables import RunnableConfig
from typing import Any

@before_model
def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    """只保留最近几条消息以适应上下文窗口。"""
    messages = state["messages"]
    
    if len(messages) <= 3:
        return None  # 不需要修改
    
    # 保留第一条消息（通常是系统消息）
    first_msg = messages[0]
    # 保留最近的消息
    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]
    new_messages = [first_msg] + recent_messages
    
    return {
        "messages": [
            RemoveMessage(id=REMOVE_ALL_MESSAGES),
            *new_messages
        ]
    }

agent = create_agent(
    "gpt-4o",
    tools=[],
    middleware=[trim_messages],
    checkpointer=InMemorySaver(),
)

config: RunnableConfig = {"configurable": {"thread_id": "1"}}

agent.invoke({"messages": "你好，我叫小明"}, config)
agent.invoke({"messages": "写一首关于猫的短诗"}, config)
agent.invoke({"messages": "现在写一首关于狗的"}, config)
final_response = agent.invoke({"messages": "我叫什么名字？"}, config)

final_response["messages"][-1].pretty_print()
"""
================================== Ai Message ==================================
你叫小明。你之前告诉我的。
如果你想让我用昵称或其他名字称呼你，随时告诉我。
"""
```

#### 删除消息

你可以从图状态中删除消息来管理消息历史。这在你想要移除特定消息或清除整个消息历史时很有用。

要使 `RemoveMessage` 生效，需要使用带有 `add_messages` reducer 的状态键。默认的 `AgentState` 已经提供了这个。

删除特定消息：

```python
from langchain.messages import RemoveMessage

def delete_messages(state):
    messages = state["messages"]
    if len(messages) > 2:
        # 移除最早的两条消息
        return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}
```

删除所有消息：

```python
from langgraph.graph.message import REMOVE_ALL_MESSAGES

def delete_messages(state):
    return {"messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}
```

> ⚠️ 删除消息时，**确保**生成的消息历史是有效的。检查你使用的 LLM 提供商的限制。例如：
> - 某些提供商要求消息历史以 `user` 消息开头
> - 大多数提供商要求带有工具调用的 `assistant` 消息后面跟着相应的 `tool` 结果消息

完整示例：

```python
from langchain.messages import RemoveMessage
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import after_model
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.runtime import Runtime
from langchain_core.runnables import RunnableConfig

@after_model
def delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None:
    """删除旧消息以保持对话可管理。"""
    messages = state["messages"]
    if len(messages) > 2:
        # 移除最早的两条消息
        return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}
    return None

agent = create_agent(
    "gpt-4o-mini",
    tools=[],
    system_prompt="请简洁明了。",
    middleware=[delete_old_messages],
    checkpointer=InMemorySaver(),
)

config: RunnableConfig = {"configurable": {"thread_id": "1"}}

for event in agent.stream(
    {"messages": [{"role": "user", "content": "你好！我叫小明"}]},
    config,
    stream_mode="values",
):
    print([(message.type, message.content) for message in event["messages"]])

for event in agent.stream(
    {"messages": [{"role": "user", "content": "我叫什么名字？"}]},
    config,
    stream_mode="values",
):
    print([(message.type, message.content) for message in event["messages"]])
```

输出：
```
[('human', '你好！我叫小明')]
[('human', '你好！我叫小明'), ('ai', '你好小明！很高兴认识你。有什么我可以帮助你的吗？')]
[('human', '你好！我叫小明'), ('ai', '你好小明！很高兴认识你。有什么我可以帮助你的吗？'), ('human', '我叫什么名字？')]
[('human', '你好！我叫小明'), ('ai', '你好小明！很高兴认识你。有什么我可以帮助你的吗？'), ('human', '我叫什么名字？'), ('ai', '你叫小明。今天有什么我可以帮助你的吗，小明？')]
[('human', '我叫什么名字？'), ('ai', '你叫小明。今天有什么我可以帮助你的吗，小明？')]
```


#### 总结消息

裁剪或删除消息的问题在于，你可能会因为消息队列的裁剪而丢失信息。

因此，一些应用可以从更复杂的方法中受益——使用聊天模型总结消息历史。

```
┌─────────────────────────────────────────────────────────────┐
│                     消息历史                                 │
├─────────────────────────────────────────────────────────────┤
│  [旧消息1] [旧消息2] [旧消息3] ... [最近消息1] [最近消息2]    │
│       ↓                                                      │
│    总结为一条摘要消息                                         │
│       ↓                                                      │
│  [摘要] [最近消息1] [最近消息2]                               │
└─────────────────────────────────────────────────────────────┘
```

使用内置的 `SummarizationMiddleware` 在 Agent 中总结消息历史：

```python
from langchain.agents import create_agent
from langchain.agents.middleware import SummarizationMiddleware
from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.runnables import RunnableConfig

checkpointer = InMemorySaver()

agent = create_agent(
    model="gpt-4o",
    tools=[],
    middleware=[
        SummarizationMiddleware(
            model="gpt-4o-mini",      # 用于总结的模型（可以用更便宜的）
            trigger=("tokens", 4000), # 当 token 数超过 4000 时触发总结
            keep=("messages", 20)     # 保留最近 20 条消息
        )
    ],
    checkpointer=checkpointer,
)

config: RunnableConfig = {"configurable": {"thread_id": "1"}}

agent.invoke({"messages": "你好，我叫小明"}, config)
agent.invoke({"messages": "写一首关于猫的短诗"}, config)
agent.invoke({"messages": "现在写一首关于狗的"}, config)
final_response = agent.invoke({"messages": "我叫什么名字？"}, config)

final_response["messages"][-1].pretty_print()
"""
================================== Ai Message ==================================
你叫小明！
"""
```

`SummarizationMiddleware` 参数：

| 参数 | 说明 |
|------|------|
| `model` | 用于生成摘要的模型 |
| `trigger` | 触发总结的条件，如 `("tokens", 4000)` |
| `keep` | 保留的最近消息数量，如 `("messages", 20)` |

### 访问短期记忆

你可以通过多种方式访问和修改 Agent 的短期记忆（状态）。

#### 在工具中访问

##### 读取短期记忆

使用 `runtime` 参数（类型为 `ToolRuntime`）在工具中访问短期记忆（状态）。

`runtime` 参数对工具签名是隐藏的（模型看不到它），但工具可以通过它访问状态：

```python
from langchain.agents import create_agent, AgentState
from langchain.tools import tool, ToolRuntime

class CustomState(AgentState):
    user_id: str

@tool
def get_user_info(runtime: ToolRuntime) -> str:
    """查找用户信息。"""
    user_id = runtime.state["user_id"]
    return "用户是张三" if user_id == "user_123" else "未知用户"

agent = create_agent(
    model="gpt-4o-mini",
    tools=[get_user_info],
    state_schema=CustomState,
)

result = agent.invoke({
    "messages": "查找用户信息",
    "user_id": "user_123"
})

print(result["messages"][-1].content)
# > 用户是张三。
```

##### 从工具写入短期记忆

要在执行过程中修改 Agent 的短期记忆（状态），可以直接从工具返回状态更新。

这对于持久化中间结果或使信息可供后续工具或提示访问很有用：

```python
from langchain.tools import tool, ToolRuntime
from langchain_core.runnables import RunnableConfig
from langchain.messages import ToolMessage
from langchain.agents import create_agent, AgentState
from langgraph.types import Command
from pydantic import BaseModel

class CustomState(AgentState):
    user_name: str

class CustomContext(BaseModel):
    user_id: str

@tool
def update_user_info(runtime: ToolRuntime[CustomContext, CustomState]) -> Command:
    """查找并更新用户信息。"""
    user_id = runtime.context.user_id
    name = "张三" if user_id == "user_123" else "未知用户"
    
    return Command(
        update={
            "user_name": name,
            # 更新消息历史
            "messages": [
                ToolMessage(
                    "成功查找用户信息",
                    tool_call_id=runtime.tool_call_id
                )
            ]
        }
    )

@tool
def greet(runtime: ToolRuntime[CustomContext, CustomState]) -> str | Command:
    """找到用户信息后用于问候用户。"""
    user_name = runtime.state.get("user_name", None)
    
    if user_name is None:
        return Command(
            update={
                "messages": [
                    ToolMessage(
                        "请先调用 'update_user_info' 工具获取用户名称。",
                        tool_call_id=runtime.tool_call_id
                    )
                ]
            }
        )
    
    return f"你好 {user_name}！"

agent = create_agent(
    model="gpt-4o-mini",
    tools=[update_user_info, greet],
    state_schema=CustomState,
    context_schema=CustomContext,
)

agent.invoke(
    {"messages": [{"role": "user", "content": "问候用户"}]},
    context=CustomContext(user_id="user_123"),
)
```


#### 在提示中访问

在中间件中访问短期记忆（状态），根据对话历史或自定义状态字段创建动态提示：

```python
from langchain.agents import create_agent
from typing import TypedDict
from langchain.agents.middleware import dynamic_prompt, ModelRequest

class CustomContext(TypedDict):
    user_name: str

def get_weather(city: str) -> str:
    """获取城市的天气。"""
    return f"{city}的天气总是阳光明媚！"

@dynamic_prompt
def dynamic_system_prompt(request: ModelRequest) -> str:
    user_name = request.runtime.context["user_name"]
    system_prompt = f"你是一个有帮助的助手。称呼用户为 {user_name}。"
    return system_prompt

agent = create_agent(
    model="gpt-4o-mini",
    tools=[get_weather],
    middleware=[dynamic_system_prompt],
    context_schema=CustomContext,
)

result = agent.invoke(
    {"messages": [{"role": "user", "content": "旧金山的天气怎么样？"}]},
    context=CustomContext(user_name="张三"),
)

for msg in result["messages"]:
    msg.pretty_print()
```

输出：
```
================================ Human Message =================================
旧金山的天气怎么样？
================================== Ai Message ==================================
Tool Calls:
  get_weather (call_WFQlOGn4b2yoJrv7cih342FG)
  Call ID: call_WFQlOGn4b2yoJrv7cih342FG
    Args:
      city: San Francisco
================================= Tool Message =================================
Name: get_weather
旧金山的天气总是阳光明媚！
================================== Ai Message ==================================
张三，旧金山的天气总是阳光明媚！
```

#### 在 before_model 中访问

在 `@before_model` 中间件中访问短期记忆（状态），在模型调用前处理消息：

```mermaid
graph TD
    S(["__start__"])
    PRE(before_model)
    MODEL(model)
    TOOLS(tools)
    END(["__end__"])
    
    S --> PRE
    PRE --> MODEL
    MODEL -.-> TOOLS
    MODEL -.-> END
    TOOLS --> PRE
```

```python
from langchain.messages import RemoveMessage
from langgraph.graph.message import REMOVE_ALL_MESSAGES
from langgraph.checkpoint.memory import InMemorySaver
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import before_model
from langchain_core.runnables import RunnableConfig
from langgraph.runtime import Runtime
from typing import Any

@before_model
def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    """只保留最近几条消息以适应上下文窗口。"""
    messages = state["messages"]
    
    if len(messages) <= 3:
        return None  # 不需要修改
    
    first_msg = messages[0]
    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]
    new_messages = [first_msg] + recent_messages
    
    return {
        "messages": [
            RemoveMessage(id=REMOVE_ALL_MESSAGES),
            *new_messages
        ]
    }

agent = create_agent(
    "gpt-4o-mini",
    tools=[],
    middleware=[trim_messages],
    checkpointer=InMemorySaver()
)

config: RunnableConfig = {"configurable": {"thread_id": "1"}}

agent.invoke({"messages": "你好，我叫小明"}, config)
agent.invoke({"messages": "写一首关于猫的短诗"}, config)
agent.invoke({"messages": "现在写一首关于狗的"}, config)
final_response = agent.invoke({"messages": "我叫什么名字？"}, config)

final_response["messages"][-1].pretty_print()
"""
================================== Ai Message ==================================
你叫小明。你之前告诉我的。
如果你想让我用昵称或其他名字称呼你，随时告诉我。
"""
```

#### 在 after_model 中访问

在 `@after_model` 中间件中访问短期记忆（状态），在模型调用后处理消息：

```mermaid
graph TD
    S(["__start__"])
    MODEL(model)
    POST(after_model)
    TOOLS(tools)
    END(["__end__"])
    
    S --> MODEL
    MODEL --> POST
    POST -.-> END
    POST -.-> TOOLS
    TOOLS --> MODEL
```

```python
from langchain.messages import RemoveMessage
from langgraph.checkpoint.memory import InMemorySaver
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import after_model
from langgraph.runtime import Runtime

@after_model
def validate_response(state: AgentState, runtime: Runtime) -> dict | None:
    """移除包含敏感词的消息。"""
    STOP_WORDS = ["password", "secret"]
    
    last_message = state["messages"][-1]
    if any(word in last_message.content for word in STOP_WORDS):
        return {"messages": [RemoveMessage(id=last_message.id)]}
    
    return None

agent = create_agent(
    model="gpt-4o-mini",
    tools=[],
    middleware=[validate_response],
    checkpointer=InMemorySaver(),
)
```

---


## 长期记忆（Store）

LangChain Agent 使用 LangGraph 持久化来实现长期记忆。这是一个更高级的主题，需要了解 LangGraph 才能使用。

### 记忆存储结构

LangGraph 将长期记忆存储为 JSON 文档在 Store 中。

每条记忆按以下方式组织：
- **namespace**（命名空间）：类似文件夹，通常包含用户 ID 或组织 ID
- **key**（键）：类似文件名，唯一标识一条记忆

```mermaid
graph TB
    Store[(Store)] --> NS1["namespace: (user_123, chitchat)"]
    Store --> NS2["namespace: (user_456, chitchat)"]
    Store --> NS3["namespace: (user_123, work)"]
    
    NS1 --> K1["key: preferences"]
    NS1 --> K2["key: history"]
    NS2 --> K3["key: preferences"]
    NS3 --> K4["key: projects"]
    
    K1 --> V1["{ language: 'zh', style: 'concise' }"]
    K2 --> V2["{ topics: ['AI', 'Python'] }"]
```

### 基本操作

```python
from langgraph.store.memory import InMemoryStore

def embed(texts: list[str]) -> list[list[float]]:
    # 替换为实际的嵌入函数或 LangChain embeddings 对象
    return [[1.0, 2.0] * len(texts)]

# InMemoryStore 将数据保存到内存字典
# 生产环境使用数据库支持的 Store
store = InMemoryStore(index={"embed": embed, "dims": 2})

user_id = "my-user"
application_context = "chitchat"
namespace = (user_id, application_context)

# 写入记忆
store.put(
    namespace,
    "a-memory",  # key
    {
        "rules": [
            "用户喜欢简短直接的语言",
            "用户只说英语和 Python",
        ],
        "my-key": "my-value",
    },
)

# 通过 ID 获取记忆
item = store.get(namespace, "a-memory")

# 在命名空间内搜索记忆
# 支持内容过滤和向量相似度排序
items = store.search(
    namespace, 
    filter={"my-key": "my-value"}, 
    query="language preferences"
)
```

### Store 操作一览

| 操作 | 方法 | 说明 |
|------|------|------|
| 写入 | `store.put(namespace, key, data)` | 存储或更新一条记忆 |
| 读取 | `store.get(namespace, key)` | 获取指定记忆 |
| 搜索 | `store.search(namespace, filter, query)` | 按条件搜索记忆 |
| 删除 | `store.delete(namespace, key)` | 删除指定记忆 |

### 在工具中读取长期记忆

```python
from dataclasses import dataclass
from langchain.agents import create_agent
from langchain.tools import tool, ToolRuntime
from langgraph.store.memory import InMemoryStore

@dataclass
class Context:
    user_id: str

# 创建 Store（生产环境使用数据库支持的 Store）
store = InMemoryStore()

# 预先写入示例数据
store.put(
    ("users",),           # 命名空间
    "user_123",           # 键（用户 ID）
    {
        "name": "张三",
        "language": "中文",
    }
)

@tool
def get_user_info(runtime: ToolRuntime[Context]) -> str:
    """查询用户信息"""
    # 从 runtime 访问 store
    store = runtime.store
    user_id = runtime.context.user_id
    
    # 从 store 检索数据
    user_info = store.get(("users",), user_id)
    return str(user_info.value) if user_info else "未知用户"

agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[get_user_info],
    store=store,  # 传递 store 给 agent
    context_schema=Context
)

# 运行 agent
agent.invoke(
    {"messages": [{"role": "user", "content": "查询用户信息"}]},
    context=Context(user_id="user_123")
)
```

#### 数据流

```mermaid
sequenceDiagram
    participant User as 用户
    participant Agent as Agent
    participant Tool as get_user_info
    participant Store as Store

    User->>Agent: "查询用户信息"
    Agent->>Tool: 调用工具
    Tool->>Store: store.get(("users",), "user_123")
    Store-->>Tool: { name: "张三", language: "中文" }
    Tool-->>Agent: "张三, 中文"
    Agent-->>User: "用户张三，使用中文"
```

### 在工具中写入长期记忆

```python
from dataclasses import dataclass
from typing_extensions import TypedDict
from langchain.agents import create_agent
from langchain.tools import tool, ToolRuntime
from langgraph.store.memory import InMemoryStore

store = InMemoryStore()

@dataclass
class Context:
    user_id: str

# 定义用户信息结构
class UserInfo(TypedDict):
    name: str

@tool
def save_user_info(user_info: UserInfo, runtime: ToolRuntime[Context]) -> str:
    """保存用户信息"""
    store = runtime.store
    user_id = runtime.context.user_id
    
    # 存储数据 (namespace, key, data)
    store.put(("users",), user_id, user_info)
    return "成功保存用户信息"

agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[save_user_info],
    store=store,
    context_schema=Context
)

# 运行 agent
agent.invoke(
    {"messages": [{"role": "user", "content": "我叫张三"}]},
    context=Context(user_id="user_123")
)

# 直接访问 store 获取值
store.get(("users",), "user_123").value
# 输出: {'name': '张三'}
```

### 完整示例：个性化助手

```python
from dataclasses import dataclass
from typing_extensions import TypedDict
from langchain.agents import create_agent
from langchain.tools import tool, ToolRuntime
from langgraph.store.memory import InMemoryStore

@dataclass
class Context:
    user_id: str

class UserPreferences(TypedDict):
    language: str
    style: str  # concise / detailed
    interests: list[str]

store = InMemoryStore()

@tool
def get_preferences(runtime: ToolRuntime[Context]) -> str:
    """获取用户偏好设置"""
    user_id = runtime.context.user_id
    prefs = runtime.store.get(("preferences",), user_id)
    if prefs:
        return f"语言: {prefs.value['language']}, 风格: {prefs.value['style']}, 兴趣: {prefs.value['interests']}"
    return "未找到用户偏好"

@tool
def save_preferences(
    language: str,
    style: str,
    interests: list[str],
    runtime: ToolRuntime[Context]
) -> str:
    """保存用户偏好设置"""
    user_id = runtime.context.user_id
    runtime.store.put(
        ("preferences",), 
        user_id, 
        {"language": language, "style": style, "interests": interests}
    )
    return "偏好已保存"

@tool
def add_interest(interest: str, runtime: ToolRuntime[Context]) -> str:
    """添加用户兴趣"""
    user_id = runtime.context.user_id
    prefs = runtime.store.get(("preferences",), user_id)
    
    if prefs:
        interests = prefs.value.get("interests", [])
        if interest not in interests:
            interests.append(interest)
            prefs.value["interests"] = interests
            runtime.store.put(("preferences",), user_id, prefs.value)
            return f"已添加兴趣: {interest}"
        return f"兴趣 {interest} 已存在"
    return "请先设置偏好"

agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[get_preferences, save_preferences, add_interest],
    store=store,
    context_schema=Context,
    prompt="你是一个个性化助手，可以记住用户的偏好设置。"
)
```

---


## 记忆类型对比

### Store vs State vs Context

```mermaid
graph LR
    subgraph "Context (配置)"
        C1[user_id]
        C2[api_key]
        C3[db_connection]
    end
    
    subgraph "State (会话记忆)"
        S1[messages]
        S2[tool_results]
        S3[session_data]
    end
    
    subgraph "Store (长期记忆)"
        L1[user_preferences]
        L2[historical_insights]
        L3[learned_patterns]
    end
    
    C1 -->|只读配置| Tool
    S1 -->|当前会话| Model
    L1 -->|跨会话| Tool
```

| 概念 | 生命周期 | 访问方式 | 典型内容 |
|------|----------|----------|----------|
| Context | 单次调用 | `runtime.context` | 用户 ID、API 密钥、配置 |
| State | 当前会话 | `runtime.state` | 消息历史、临时数据 |
| Store | 跨会话 | `runtime.store` | 用户偏好、历史洞察 |

### 短期记忆 vs 长期记忆

| 特性 | 短期记忆 (State) | 长期记忆 (Store) |
|------|------------------|------------------|
| **生命周期** | 当前会话 | 跨会话持久化 |
| **存储内容** | 对话消息、临时状态 | 用户偏好、历史数据、洞察 |
| **访问范围** | 单次对话 | 跨多次对话 |
| **典型用途** | 上下文窗口管理 | 用户画像、个性化 |
| **实现方式** | Checkpointer | Store |
| **访问方式** | `runtime.state` | `runtime.store` |
| **数据结构** | AgentState (TypedDict) | JSON 文档 |
| **组织方式** | thread_id | namespace + key |

### 何时使用哪种记忆？

| 场景 | 推荐 | 原因 |
|------|------|------|
| 对话历史 | 短期记忆 | 只在当前会话有效 |
| 用户偏好设置 | 长期记忆 | 需要跨会话保存 |
| 临时计算结果 | 短期记忆 | 会话结束后不需要 |
| 用户画像数据 | 长期记忆 | 需要长期积累 |
| 工具调用结果 | 短期记忆 | 只在当前会话使用 |
| 历史交互洞察 | 长期记忆 | 用于个性化推荐 |
| 会话计数器 | 短期记忆 | 只跟踪当前会话 |
| 用户行为模式 | 长期记忆 | 需要跨会话分析 |

---

## 最佳实践

### 短期记忆最佳实践

1. **选择合适的 Checkpointer**
   - 开发环境：`InMemorySaver`（简单快速）
   - 生产环境：`PostgresSaver`（持久化可靠）

2. **管理上下文窗口**
   - 使用 `SummarizationMiddleware` 自动总结长对话
   - 使用 `@before_model` 裁剪消息
   - 删除不必要的消息以节省 token

3. **自定义状态设计**
   - 只添加必要的字段
   - 使用 TypedDict 定义清晰的结构
   - 在工具中通过 `runtime.state` 访问

4. **线程管理**
   - 为每个独立对话使用唯一的 `thread_id`
   - 定期清理过期的线程数据

### 长期记忆最佳实践

1. **命名空间设计**
   - 使用有意义的命名空间，如 `(user_id, context)`
   - 按用户或组织隔离数据
   - 考虑数据访问模式

2. **数据结构**
   - 使用 JSON 格式存储结构化数据
   - 保持数据扁平化，避免过深嵌套
   - 添加时间戳和版本信息

3. **性能优化**
   - 使用 `store.search()` 的过滤功能
   - 考虑使用向量嵌入进行语义搜索
   - 定期清理过期数据

4. **隐私和安全**
   - 不要存储敏感信息（密码、信用卡等）
   - 实现数据访问控制
   - 遵守数据保留政策

### 组合使用

```python
from dataclasses import dataclass
from langchain.agents import create_agent, AgentState
from langchain.tools import tool, ToolRuntime
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.store.memory import InMemoryStore

# 自定义短期记忆状态
class CustomState(AgentState):
    session_count: int  # 当前会话的请求计数

# 上下文
@dataclass
class Context:
    user_id: str

# 工具：同时使用短期和长期记忆
@tool
def personalized_response(query: str, runtime: ToolRuntime[Context, CustomState]) -> str:
    """提供个性化响应"""
    # 访问短期记忆（当前会话）
    session_count = runtime.state.get("session_count", 0)
    
    # 访问长期记忆（跨会话）
    user_id = runtime.context.user_id
    prefs = runtime.store.get(("preferences",), user_id)
    
    if prefs:
        style = prefs.value.get("style", "normal")
        response = f"[会话请求 #{session_count}] 根据你的偏好（{style}）回答: {query}"
    else:
        response = f"[会话请求 #{session_count}] 回答: {query}"
    
    return response

# 创建 Agent
store = InMemoryStore()
checkpointer = InMemorySaver()

agent = create_agent(
    model="gpt-4o",
    tools=[personalized_response],
    state_schema=CustomState,
    context_schema=Context,
    checkpointer=checkpointer,  # 短期记忆
    store=store,                # 长期记忆
)

# 使用
agent.invoke(
    {
        "messages": [{"role": "user", "content": "你好"}],
        "session_count": 1
    },
    config={"configurable": {"thread_id": "session_1"}},
    context=Context(user_id="user_123")
)
```

---

## 总结

### 短期记忆（State）

| 概念 | 说明 |
|------|------|
| `checkpointer` | 持久化状态，启用短期记忆 |
| `thread_id` | 标识不同对话会话，实现记忆隔离 |
| `AgentState` | 默认状态，包含 `messages` |
| 自定义状态 | 扩展 `AgentState` 添加额外字段 |
| 裁剪消息 | 移除旧消息以适应上下文窗口 |
| 删除消息 | 永久删除特定消息 |
| 总结消息 | 用摘要替换旧消息 |
| `@before_model` | 模型调用前处理状态 |
| `@after_model` | 模型调用后处理状态 |
| `ToolRuntime` | 在工具中访问状态和上下文 |

### 长期记忆（Store）

| 概念 | 说明 |
|------|------|
| Store | 长期记忆存储，跨会话持久化 |
| namespace | 命名空间，用于组织记忆（如用户 ID） |
| key | 记忆的唯一标识符 |
| `store.put()` | 写入或更新记忆 |
| `store.get()` | 读取指定记忆 |
| `store.search()` | 搜索记忆，支持过滤和向量相似度 |
| `runtime.store` | 在工具中访问 Store |

### 关键区别

**短期记忆**适合：
- 对话历史管理
- 会话内的临时数据
- 需要快速访问的状态

**长期记忆**适合：
- 用户偏好和设置
- 跨会话的历史数据
- 需要持久化的洞察

选择合适的记忆类型，可以让你的 Agent 既能保持对话连贯性，又能提供个性化的长期体验。
