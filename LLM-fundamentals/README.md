# LLM 学习笔记

基于 Datawhale《Happy-LLM》教程的学习记录，面向计算机专业背景，包含数学公式推导和专业概念解析。

## 学习进度

| 章节 | 内容 | 状态 | 主要知识点 |
|------|------|------|-----------|
| 第1章 | NLP基础概念 | ✅ 已完成 | 词向量、Word2Vec、ELMo、Tokenizer |
| 第2章 | Transformer架构 | ✅ 已完成 | Attention、Multi-Head、位置编码、复杂度分析 |
| 第3章 | 预训练语言模型PLM | ✅ 已完成 | BERT、GPT、LLaMA、SFT、RLHF、DPO |
| 第4章 | LLM应用与进阶 | ✅ 已完成 | Prompt、RAG、Agent、量化、评估 |
| 第5章 | 动手实践 | 🔲 待学习 | HuggingFace、微调、部署 |

## 笔记目录

- [第1章-NLP基础概念.md](./第1章-NLP基础概念.md) - 词向量演进、Word2Vec 数学推导、负采样
- [第2章-Transformer架构.md](./第2章-Transformer架构.md) - Self-Attention、QKV 机制、O(n²) 复杂度
- [第3章-预训练语言模型PLM.md](./第3章-预训练语言模型PLM.md) - MLM/CLM、Scaling Law、RLHF/DPO 数学
- [第4章-LLM应用与进阶.md](./第4章-LLM应用与进阶.md) - RAG 检索、BM25、量化原理、评估指标

## 内容特点

- 📐 **数学公式**：包含损失函数、优化目标、评估指标的完整推导
- 🔬 **专业深度**：Scaling Law、RoPE、DPO 等前沿技术的数学原理
- 📊 **对比分析**：架构对比、方法对比、复杂度分析
- 📚 **论文引用**：关键论文出处和推荐阅读

## 学习资源

- Datawhale GitHub: https://github.com/datawhalechina

---
最后更新：2025年12月
