# 混合检索与融合策略详解

## 一、为什么需要混合检索

### 1.1 单一检索方式的局限

**向量检索的问题**：
```
Query: "Python 3.9.1 安装教程"
Doc1: "Python 3.9.1 版本安装指南" ← 精确匹配
Doc2: "Python 编程入门教程" ← 语义相似但不精确

向量检索可能认为 Doc2 更相关（更多语义重叠）
但用户明确要 "3.9.1" 版本
```

**BM25 的问题**：
```
Query: "如何提高代码运行效率"
Doc: "性能优化最佳实践：减少时间复杂度..."

BM25 无法匹配（没有共同词汇）
但语义上高度相关
```


### 1.2 两种检索方式的对比

| 特性 | BM25（稀疏检索） | 向量检索（稠密检索） |
|------|------------------|----------------------|
| 匹配方式 | 精确词匹配 | 语义匹配 |
| 同义词 | ❌ 无法处理 | ✅ 自动处理 |
| 专有名词/数字 | ✅ 精确匹配 | ⚠️ 可能模糊 |
| 长尾查询 | ✅ 有效 | ⚠️ 可能不足 |
| 计算成本 | 低 | 中 |
| 可解释性 | 高 | 低 |
| 冷启动 | ✅ 无需训练 | ❌ 需要模型 |

### 1.3 混合检索的优势

**互补性**：
- BM25 擅长精确匹配、专有名词、数字
- 向量检索擅长语义理解、同义词、模糊匹配

**鲁棒性**：
- 单一方法可能在某些查询上失败
- 混合方法更稳定

---

## 二、混合检索架构

### 2.1 基本架构

```
                    Query
                      │
          ┌───────────┴───────────┐
          ↓                       ↓
    [BM25 检索]             [向量检索]
          │                       │
          ↓                       ↓
    BM25 结果               向量结果
    [(doc1, 0.8),           [(doc3, 0.95),
     (doc2, 0.6),            (doc1, 0.85),
     (doc4, 0.5)]            (doc5, 0.80)]
          │                       │
          └───────────┬───────────┘
                      ↓
                 [结果融合]
                      ↓
                 最终结果
                 [doc1, doc3, doc2, doc5, doc4]
```

### 2.2 实现框架

```python
class HybridRetriever:
    def __init__(self, bm25_index, vector_index, fusion_method='rrf'):
        self.bm25_index = bm25_index
        self.vector_index = vector_index
        self.fusion_method = fusion_method
    
    def search(self, query, top_k=10, bm25_weight=0.5):
        """
        混合检索
        """
        # BM25 检索
        bm25_results = self.bm25_index.search(query, top_k=top_k * 2)
        
        # 向量检索
        query_embedding = self.encode(query)
        vector_results = self.vector_index.search(query_embedding, top_k=top_k * 2)
        
        # 融合
        if self.fusion_method == 'rrf':
            fused = self.rrf_fusion(bm25_results, vector_results)
        elif self.fusion_method == 'weighted':
            fused = self.weighted_fusion(
                bm25_results, vector_results, bm25_weight
            )
        else:
            raise ValueError(f"Unknown fusion method: {self.fusion_method}")
        
        return fused[:top_k]
```

---

## 三、结果融合策略

### 3.1 RRF（Reciprocal Rank Fusion）

最常用的融合方法，简单有效。

**公式**：

$$RRF(d) = \sum_{r \in R} \frac{1}{k + rank_r(d)}$$

其中：
- $R$：所有排序结果列表
- $rank_r(d)$：文档 $d$ 在列表 $r$ 中的排名（从 1 开始）
- $k$：常数，通常取 60

**直觉**：排名靠前的文档贡献更大，但不会过度主导


**实现**：

```python
def rrf_fusion(rankings, k=60):
    """
    Reciprocal Rank Fusion
    
    Args:
        rankings: list of lists, 每个列表是一个排序结果
                  [(doc_id, score), ...]
        k: RRF 常数
    
    Returns:
        融合后的排序结果
    """
    scores = {}
    
    for ranking in rankings:
        for rank, (doc_id, _) in enumerate(ranking, start=1):
            if doc_id not in scores:
                scores[doc_id] = 0
            scores[doc_id] += 1 / (k + rank)
    
    # 按分数排序
    sorted_docs = sorted(scores.items(), key=lambda x: -x[1])
    
    return sorted_docs

# 示例
bm25_results = [("doc1", 0.8), ("doc2", 0.6), ("doc4", 0.5)]
vector_results = [("doc3", 0.95), ("doc1", 0.85), ("doc5", 0.80)]

fused = rrf_fusion([bm25_results, vector_results], k=60)
# doc1: 1/(60+1) + 1/(60+2) = 0.0164 + 0.0161 = 0.0325
# doc3: 1/(60+1) = 0.0164
# doc2: 1/(60+2) = 0.0161
# ...
```

**RRF 的优点**：
- 不需要分数归一化
- 对异常值不敏感
- 简单有效

**k 值的影响**：
- k 小：排名靠前的文档权重更大
- k 大：排名差异的影响减小

### 3.2 加权分数融合

将不同来源的分数归一化后加权求和。

**公式**：

$$score(d) = \alpha \cdot norm(score_{BM25}(d)) + (1-\alpha) \cdot norm(score_{vector}(d))$$

**归一化方法**：

```python
def min_max_normalize(scores):
    """Min-Max 归一化到 [0, 1]"""
    min_s = min(scores.values())
    max_s = max(scores.values())
    
    if max_s == min_s:
        return {k: 1.0 for k in scores}
    
    return {k: (v - min_s) / (max_s - min_s) for k, v in scores.items()}

def z_score_normalize(scores):
    """Z-score 归一化"""
    values = list(scores.values())
    mean = np.mean(values)
    std = np.std(values)
    
    if std == 0:
        return {k: 0.0 for k in scores}
    
    return {k: (v - mean) / std for k, v in scores.items()}
```


**实现**：

```python
def weighted_fusion(bm25_results, vector_results, alpha=0.5, 
                    normalize_fn=min_max_normalize):
    """
    加权分数融合
    
    Args:
        bm25_results: BM25 检索结果 [(doc_id, score), ...]
        vector_results: 向量检索结果 [(doc_id, score), ...]
        alpha: BM25 的权重，向量权重为 1-alpha
        normalize_fn: 归一化函数
    """
    # 转换为字典
    bm25_scores = {doc_id: score for doc_id, score in bm25_results}
    vector_scores = {doc_id: score for doc_id, score in vector_results}
    
    # 归一化
    bm25_norm = normalize_fn(bm25_scores)
    vector_norm = normalize_fn(vector_scores)
    
    # 融合
    all_docs = set(bm25_norm.keys()) | set(vector_norm.keys())
    fused_scores = {}
    
    for doc_id in all_docs:
        bm25_s = bm25_norm.get(doc_id, 0)
        vector_s = vector_norm.get(doc_id, 0)
        fused_scores[doc_id] = alpha * bm25_s + (1 - alpha) * vector_s
    
    # 排序
    sorted_docs = sorted(fused_scores.items(), key=lambda x: -x[1])
    
    return sorted_docs
```

**权重选择**：
- α = 0.5：平等对待两种方法
- α > 0.5：更信任 BM25（精确匹配重要）
- α < 0.5：更信任向量检索（语义理解重要）

### 3.3 Convex Combination

类似加权融合，但使用 softmax 归一化：

```python
def convex_combination(bm25_results, vector_results, alpha=0.5, temperature=1.0):
    """
    Convex Combination with softmax normalization
    """
    def softmax_normalize(scores, temperature):
        values = np.array(list(scores.values()))
        exp_values = np.exp(values / temperature)
        softmax_values = exp_values / exp_values.sum()
        return dict(zip(scores.keys(), softmax_values))
    
    bm25_scores = {doc_id: score for doc_id, score in bm25_results}
    vector_scores = {doc_id: score for doc_id, score in vector_results}
    
    bm25_norm = softmax_normalize(bm25_scores, temperature)
    vector_norm = softmax_normalize(vector_scores, temperature)
    
    # 融合
    all_docs = set(bm25_norm.keys()) | set(vector_norm.keys())
    fused_scores = {}
    
    for doc_id in all_docs:
        bm25_s = bm25_norm.get(doc_id, 0)
        vector_s = vector_norm.get(doc_id, 0)
        fused_scores[doc_id] = alpha * bm25_s + (1 - alpha) * vector_s
    
    return sorted(fused_scores.items(), key=lambda x: -x[1])
```

### 3.4 学习排序（Learning to Rank）

训练一个模型来学习最优的融合方式。

**特征**：
- BM25 分数
- 向量相似度
- 排名位置
- 查询特征（长度、类型等）
- 文档特征（长度、领域等）

```python
class LearnedFusion:
    def __init__(self, model_path=None):
        if model_path:
            self.model = load_model(model_path)
        else:
            self.model = self._build_model()
    
    def _build_model(self):
        """构建融合模型"""
        from sklearn.ensemble import GradientBoostingClassifier
        return GradientBoostingClassifier()
    
    def extract_features(self, query, doc, bm25_score, vector_score, 
                         bm25_rank, vector_rank):
        """提取特征"""
        return [
            bm25_score,
            vector_score,
            1 / (60 + bm25_rank),  # RRF 特征
            1 / (60 + vector_rank),
            len(query.split()),  # 查询长度
            len(doc.split()),    # 文档长度
            bm25_score * vector_score,  # 交叉特征
        ]
    
    def train(self, training_data):
        """
        训练融合模型
        
        training_data: [(query, doc, bm25_score, vector_score, 
                        bm25_rank, vector_rank, label), ...]
        """
        X = []
        y = []
        
        for item in training_data:
            features = self.extract_features(*item[:-1])
            X.append(features)
            y.append(item[-1])  # 相关性标签
        
        self.model.fit(X, y)
    
    def fuse(self, query, candidates):
        """
        使用学习的模型融合结果
        """
        scored_candidates = []
        
        for doc_id, doc_text, bm25_score, vector_score, bm25_rank, vector_rank in candidates:
            features = self.extract_features(
                query, doc_text, bm25_score, vector_score, bm25_rank, vector_rank
            )
            score = self.model.predict_proba([features])[0][1]
            scored_candidates.append((doc_id, score))
        
        return sorted(scored_candidates, key=lambda x: -x[1])
```


---

## 四、高级混合策略

### 4.1 自适应权重

根据查询特征动态调整权重：

```python
class AdaptiveHybridRetriever:
    def __init__(self, bm25_index, vector_index, llm=None):
        self.bm25_index = bm25_index
        self.vector_index = vector_index
        self.llm = llm
    
    def estimate_alpha(self, query):
        """
        根据查询特征估计 BM25 权重
        """
        # 规则1：包含专有名词/数字 → 更信任 BM25
        if self._has_specific_terms(query):
            return 0.7
        
        # 规则2：短查询 → 更信任向量
        if len(query.split()) < 3:
            return 0.3
        
        # 规则3：问句 → 更信任向量
        if query.endswith('?') or query.startswith(('什么', '如何', '为什么')):
            return 0.4
        
        # 默认
        return 0.5
    
    def _has_specific_terms(self, query):
        """检查是否包含专有名词或数字"""
        import re
        # 检查数字
        if re.search(r'\d+', query):
            return True
        # 检查大写词（英文专有名词）
        if re.search(r'[A-Z]{2,}', query):
            return True
        return False
    
    def search(self, query, top_k=10):
        alpha = self.estimate_alpha(query)
        
        bm25_results = self.bm25_index.search(query, top_k=top_k * 2)
        vector_results = self.vector_index.search(query, top_k=top_k * 2)
        
        fused = weighted_fusion(bm25_results, vector_results, alpha=alpha)
        
        return fused[:top_k]
```

### 4.2 级联检索（Cascaded Retrieval）

先用一种方法粗筛，再用另一种方法精排：

```python
class CascadedRetriever:
    def __init__(self, bm25_index, vector_index, cross_encoder):
        self.bm25_index = bm25_index
        self.vector_index = vector_index
        self.cross_encoder = cross_encoder
    
    def search(self, query, top_k=10):
        """
        级联检索：BM25 → 向量 → Cross-encoder
        """
        # 阶段1：BM25 粗筛（快速，召回大量候选）
        bm25_candidates = self.bm25_index.search(query, top_k=100)
        
        # 阶段2：向量重排（语义理解）
        candidate_ids = [doc_id for doc_id, _ in bm25_candidates]
        candidate_embeddings = self.vector_index.get_embeddings(candidate_ids)
        query_embedding = self.vector_index.encode(query)
        
        vector_scores = []
        for doc_id, doc_emb in zip(candidate_ids, candidate_embeddings):
            score = cosine_similarity(query_embedding, doc_emb)
            vector_scores.append((doc_id, score))
        
        vector_scores.sort(key=lambda x: -x[1])
        top_candidates = vector_scores[:50]
        
        # 阶段3：Cross-encoder 精排（最准确）
        final_scores = []
        for doc_id, _ in top_candidates:
            doc_text = self.get_doc_text(doc_id)
            score = self.cross_encoder.predict(query, doc_text)
            final_scores.append((doc_id, score))
        
        final_scores.sort(key=lambda x: -x[1])
        
        return final_scores[:top_k]
```

### 4.3 多路召回 + 统一重排

```python
class MultiPathRetriever:
    def __init__(self, retrievers, reranker):
        """
        retrievers: dict of {name: retriever}
        reranker: 重排模型
        """
        self.retrievers = retrievers
        self.reranker = reranker
    
    def search(self, query, top_k=10, recall_per_path=50):
        """
        多路召回 + 统一重排
        """
        # 多路召回
        all_candidates = set()
        path_results = {}
        
        for name, retriever in self.retrievers.items():
            results = retriever.search(query, top_k=recall_per_path)
            path_results[name] = results
            all_candidates.update([doc_id for doc_id, _ in results])
        
        # 去重后的候选
        candidates = list(all_candidates)
        
        # 统一重排
        reranked = self.reranker.rerank(query, candidates)
        
        return reranked[:top_k]
```

---

## 五、实现细节

### 5.1 并行检索

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class ParallelHybridRetriever:
    def __init__(self, bm25_index, vector_index):
        self.bm25_index = bm25_index
        self.vector_index = vector_index
        self.executor = ThreadPoolExecutor(max_workers=2)
    
    async def search_async(self, query, top_k=10):
        """异步并行检索"""
        loop = asyncio.get_event_loop()
        
        # 并行执行 BM25 和向量检索
        bm25_future = loop.run_in_executor(
            self.executor, 
            self.bm25_index.search, 
            query, top_k * 2
        )
        vector_future = loop.run_in_executor(
            self.executor,
            self.vector_index.search,
            query, top_k * 2
        )
        
        bm25_results, vector_results = await asyncio.gather(
            bm25_future, vector_future
        )
        
        # 融合
        fused = rrf_fusion([bm25_results, vector_results])
        
        return fused[:top_k]
    
    def search(self, query, top_k=10):
        """同步接口"""
        return asyncio.run(self.search_async(query, top_k))
```

### 5.2 缓存优化

```python
from functools import lru_cache
import hashlib

class CachedHybridRetriever:
    def __init__(self, bm25_index, vector_index, cache_size=1000):
        self.bm25_index = bm25_index
        self.vector_index = vector_index
        self.cache = {}
        self.cache_size = cache_size
    
    def _cache_key(self, query, top_k):
        """生成缓存键"""
        return hashlib.md5(f"{query}_{top_k}".encode()).hexdigest()
    
    def search(self, query, top_k=10, use_cache=True):
        """带缓存的检索"""
        cache_key = self._cache_key(query, top_k)
        
        if use_cache and cache_key in self.cache:
            return self.cache[cache_key]
        
        # 执行检索
        bm25_results = self.bm25_index.search(query, top_k=top_k * 2)
        vector_results = self.vector_index.search(query, top_k=top_k * 2)
        fused = rrf_fusion([bm25_results, vector_results])[:top_k]
        
        # 缓存结果
        if len(self.cache) >= self.cache_size:
            # LRU 淘汰
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
        
        self.cache[cache_key] = fused
        
        return fused
```


---

## 六、评估与调优

### 6.1 评估指标

```python
def evaluate_hybrid_retrieval(retriever, queries, ground_truth, k_values=[1, 5, 10]):
    """
    评估混合检索效果
    """
    metrics = {f'recall@{k}': [] for k in k_values}
    metrics.update({f'precision@{k}': [] for k in k_values})
    metrics['mrr'] = []
    metrics['ndcg@10'] = []
    
    for query, relevant_docs in zip(queries, ground_truth):
        results = retriever.search(query, top_k=max(k_values))
        retrieved_ids = [doc_id for doc_id, _ in results]
        
        for k in k_values:
            top_k_ids = retrieved_ids[:k]
            
            # Recall@K
            hits = len(set(top_k_ids) & set(relevant_docs))
            recall = hits / len(relevant_docs) if relevant_docs else 0
            metrics[f'recall@{k}'].append(recall)
            
            # Precision@K
            precision = hits / k
            metrics[f'precision@{k}'].append(precision)
        
        # MRR
        mrr = 0
        for i, doc_id in enumerate(retrieved_ids):
            if doc_id in relevant_docs:
                mrr = 1 / (i + 1)
                break
        metrics['mrr'].append(mrr)
        
        # NDCG@10
        ndcg = compute_ndcg(retrieved_ids[:10], relevant_docs)
        metrics['ndcg@10'].append(ndcg)
    
    # 计算平均值
    return {k: np.mean(v) for k, v in metrics.items()}

def compute_ndcg(retrieved, relevant, k=10):
    """计算 NDCG@K"""
    dcg = 0
    for i, doc_id in enumerate(retrieved[:k]):
        if doc_id in relevant:
            dcg += 1 / np.log2(i + 2)
    
    # 理想 DCG
    ideal_dcg = sum(1 / np.log2(i + 2) for i in range(min(len(relevant), k)))
    
    return dcg / ideal_dcg if ideal_dcg > 0 else 0
```

### 6.2 权重调优

```python
def tune_fusion_weights(bm25_index, vector_index, queries, ground_truth,
                        alpha_range=np.arange(0, 1.1, 0.1)):
    """
    网格搜索最优权重
    """
    best_alpha = 0.5
    best_recall = 0
    
    results = []
    
    for alpha in alpha_range:
        recalls = []
        
        for query, relevant in zip(queries, ground_truth):
            bm25_results = bm25_index.search(query, top_k=20)
            vector_results = vector_index.search(query, top_k=20)
            
            fused = weighted_fusion(bm25_results, vector_results, alpha=alpha)
            retrieved = [doc_id for doc_id, _ in fused[:10]]
            
            hits = len(set(retrieved) & set(relevant))
            recall = hits / len(relevant) if relevant else 0
            recalls.append(recall)
        
        avg_recall = np.mean(recalls)
        results.append((alpha, avg_recall))
        
        if avg_recall > best_recall:
            best_recall = avg_recall
            best_alpha = alpha
    
    return best_alpha, results

# 使用
best_alpha, tuning_results = tune_fusion_weights(
    bm25_index, vector_index, val_queries, val_labels
)
print(f"Best alpha: {best_alpha}, Recall@10: {best_recall:.4f}")
```

### 6.3 A/B 测试

```python
def ab_test_fusion_methods(queries, ground_truth, method_a, method_b, 
                           n_bootstrap=1000):
    """
    A/B 测试两种融合方法
    """
    recalls_a = []
    recalls_b = []
    
    for query, relevant in zip(queries, ground_truth):
        results_a = method_a(query)
        results_b = method_b(query)
        
        recall_a = compute_recall(results_a, relevant, k=10)
        recall_b = compute_recall(results_b, relevant, k=10)
        
        recalls_a.append(recall_a)
        recalls_b.append(recall_b)
    
    # Bootstrap 置信区间
    diff_samples = []
    for _ in range(n_bootstrap):
        indices = np.random.choice(len(recalls_a), len(recalls_a), replace=True)
        sample_a = np.mean([recalls_a[i] for i in indices])
        sample_b = np.mean([recalls_b[i] for i in indices])
        diff_samples.append(sample_b - sample_a)
    
    ci_lower = np.percentile(diff_samples, 2.5)
    ci_upper = np.percentile(diff_samples, 97.5)
    
    return {
        'mean_a': np.mean(recalls_a),
        'mean_b': np.mean(recalls_b),
        'diff': np.mean(recalls_b) - np.mean(recalls_a),
        'ci_95': (ci_lower, ci_upper),
        'significant': ci_lower > 0 or ci_upper < 0
    }
```

---

## 七、实际应用

### 7.1 Elasticsearch 混合检索

```python
from elasticsearch import Elasticsearch

def elasticsearch_hybrid_search(es, index, query, top_k=10, alpha=0.5):
    """
    Elasticsearch 混合检索
    """
    # 构建混合查询
    body = {
        "query": {
            "bool": {
                "should": [
                    # BM25
                    {
                        "match": {
                            "content": {
                                "query": query,
                                "boost": alpha
                            }
                        }
                    },
                    # KNN (向量检索)
                    {
                        "knn": {
                            "field": "embedding",
                            "query_vector": encode_query(query),
                            "k": top_k,
                            "num_candidates": top_k * 10,
                            "boost": 1 - alpha
                        }
                    }
                ]
            }
        },
        "size": top_k
    }
    
    response = es.search(index=index, body=body)
    
    return [(hit['_id'], hit['_score']) for hit in response['hits']['hits']]
```

### 7.2 Milvus + BM25 混合

```python
from pymilvus import Collection
from rank_bm25 import BM25Okapi

class MilvusBM25Hybrid:
    def __init__(self, collection_name, documents):
        # Milvus 向量索引
        self.collection = Collection(collection_name)
        
        # BM25 索引
        tokenized_docs = [doc.split() for doc in documents]
        self.bm25 = BM25Okapi(tokenized_docs)
        self.documents = documents
    
    def search(self, query, top_k=10):
        # BM25 检索
        tokenized_query = query.split()
        bm25_scores = self.bm25.get_scores(tokenized_query)
        bm25_top_k = np.argsort(bm25_scores)[-top_k*2:][::-1]
        bm25_results = [(i, bm25_scores[i]) for i in bm25_top_k]
        
        # Milvus 向量检索
        query_embedding = encode(query)
        milvus_results = self.collection.search(
            data=[query_embedding],
            anns_field="embedding",
            param={"metric_type": "IP", "params": {"nprobe": 10}},
            limit=top_k * 2
        )
        vector_results = [(hit.id, hit.score) for hit in milvus_results[0]]
        
        # RRF 融合
        fused = rrf_fusion([bm25_results, vector_results])
        
        return fused[:top_k]
```

---

## 八、最佳实践

### 8.1 选择建议

| 场景 | 推荐方案 |
|------|----------|
| 通用搜索 | RRF (α=0.5) |
| 精确匹配重要 | 加权融合 (α=0.7) |
| 语义理解重要 | 加权融合 (α=0.3) |
| 有标注数据 | 学习排序 |
| 延迟敏感 | RRF（无需归一化） |

### 8.2 常见问题

| 问题 | 可能原因 | 解决方案 |
|------|----------|----------|
| 混合效果不如单一方法 | 权重不合适 | 调优权重 |
| 延迟太高 | 串行检索 | 并行检索 |
| 结果不稳定 | 分数尺度差异大 | 使用 RRF |
| 某类查询效果差 | 固定权重不适应 | 自适应权重 |

### 8.3 调优流程

1. **基线**：先测试单独的 BM25 和向量检索
2. **简单融合**：尝试 RRF (k=60)
3. **权重调优**：网格搜索最优 α
4. **自适应**：根据查询特征动态调整
5. **学习排序**：如果有标注数据，训练融合模型
